# -*- coding: utf-8 -*-
"""machine-learning-in-medicine-practice-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sCfJKUrnPexdqZSvDyaJ2v3JhnZMSPYq
"""

from google.colab import drive
import os
import matplotlib.pyplot as plt
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
import torch
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler

# Mount Google Drive
drive.mount('/content/drive')

# Define the dataset directory paths
training_set_dir = '/content/drive/MyDrive/Dataset for bioimages/training_set'
test_set_dir = '/content/drive/MyDrive/Dataset for bioimages/test_set'

class UltrasoundDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.imgs = sorted([x for x in os.listdir(img_dir) if "Annotation" not in x])
        self.masks = sorted([x for x in os.listdir(img_dir) if "Annotation" in x])

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.imgs[idx])
        mask_path = os.path.join(self.img_dir, self.masks[idx])
        image = Image.open(img_path)
        mask = Image.open(mask_path)
        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)
        return image, mask

# Define the transformation (3 channels to 1 channel)
transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),
                                transforms.Resize((256, 256)),
                                transforms.ToTensor()])

# Create the datasets
train_dataset = UltrasoundDataset(img_dir=training_set_dir, transform=transform)
test_dataset = UltrasoundDataset(img_dir=test_set_dir, transform=transform)

# 80% of the training data will be used for training, 10% for validation, and 10% for testing
# Create the indices
dataset_size = len(train_dataset)
indices = list(range(dataset_size))
np.random.shuffle(indices)
split = int(np.floor(0.1 * dataset_size))
train_indices, val_indices, test_indices = indices[split*2:], indices[:split], indices[split:split*2]

# Create the samplers
train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)
test_sampler = SubsetRandomSampler(test_indices)

# Create the data loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, sampler=train_sampler)
val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, sampler=val_sampler)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, sampler=test_sampler)

import torch
import torch.nn as nn
# import torchsummary
from scipy.ndimage import gaussian_filter


def double_conv(in_channels, out_channels):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, 3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_channels, out_channels, 3, padding=1),
        nn.ReLU(inplace=True)
    )

class UNet(nn.Module):

    def __init__(self, n_class):
        super().__init__()

        self.dconv_down1 = double_conv(1, 64)
        self.dconv_down2 = double_conv(64, 128)
        self.dconv_down3 = double_conv(128, 256)
        self.dconv_down4 = double_conv(256, 512)
        self.dconv_down5 = double_conv(512, 1024)
        self.dconv_down6 = double_conv(1024, 2048)
        self.maxpool = nn.MaxPool2d(2)
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

        self.dconv_up5 = double_conv(1024 + 2048, 1024)
        self.dconv_up4 = double_conv(512 + 1024, 512)
        self.dconv_up3 = double_conv(256 + 512, 256)
        self.dconv_up2 = double_conv(128 + 256, 128)
        self.dconv_up1 = double_conv(128 + 64, 64)

        self.conv_last = nn.Conv2d(64, n_class, 1)

    def forward(self, x):
        conv1 = self.dconv_down1(x)
        x = self.maxpool(conv1)

        conv2 = self.dconv_down2(x)
        x = self.maxpool(conv2)

        conv3 = self.dconv_down3(x)
        x = self.maxpool(conv3)

        conv4 = self.dconv_down4(x)
        x = self.maxpool(conv4)

        conv5 = self.dconv_down5(x)
        x = self.maxpool(conv5)

        x = self.dconv_down6(x)

        x = self.upsample(x)
        x = torch.cat([x, conv5], dim=1)

        x = self.dconv_up5(x)
        x = self.upsample(x)
        x = torch.cat([x, conv4], dim=1)

        x = self.dconv_up4(x)
        x = self.upsample(x)
        x = torch.cat([x, conv3], dim=1)

        x = self.dconv_up3(x)
        x = self.upsample(x)
        x = torch.cat([x, conv2], dim=1)

        x = self.dconv_up2(x)
        x = self.upsample(x)
        x = torch.cat([x, conv1], dim=1)

        x = self.dconv_up1(x)

        out = self.conv_last(x)

        return out

# # Summary of the model
# model = UNet(n_class=1)
# torchsummary.summary(model, (1, 256, 256))

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(n_class=1).to(device)
# Loss function: Binary Cross Entropy
criterion = nn.BCEWithLogitsLoss()
# Optimizer: Adam
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

from tqdm import tqdm
def train(model, train_loader, valid_loader, criterion, optimizer, n_epochs=10):
    loss_train = []
    loss_valid = []
    for epoch in range(n_epochs):
        model.train()
        running_loss = 0.0
        for data in tqdm(train_loader):
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()


        loss_train.append(running_loss/len(train_loader))
        print(f"Epoch {epoch+1}/{n_epochs} - Loss: {running_loss/len(train_loader)}")
        torch.save(model.state_dict(), 'last.pth')
        model.eval()
        running_loss = 0.0
        with torch.no_grad():
            for data in valid_loader:
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                running_loss += loss.item()
                # Plot the training and validation loss

            loss_valid.append(running_loss/len(valid_loader))
            print(f"Validation Loss: {running_loss/len(valid_loader)}")
    return loss_train, loss_valid

loss_train, loss_valid = train(model, train_loader, val_loader, criterion, optimizer, n_epochs=5)

# Plot the training and validation loss
import matplotlib.pyplot as plt
plt.plot(loss_train, label='Training loss')
plt.plot(loss_valid, label='Validation loss')
plt.legend()
plt.show()

# Save the model
torch.save(model.state_dict(), 'model_bce.pth')

# Make predictions on the test set and use MAE as evaluation metric
from sklearn.metrics import mean_absolute_error

model.eval()
y_true = []
y_pred = []
with torch.no_grad():
    for data in test_loader:
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        y_true.append(labels.cpu().numpy())
        y_pred.append(outputs.cpu().numpy())
y_true = np.concatenate(y_true)
y_pred = np.concatenate(y_pred)
mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())
print(f"Mean Absolute Error: {mae}")
def iou_score(y_true, y_pred):
    intersection = np.logical_and(y_true, y_pred)
    union = np.logical_or(y_true, y_pred)
    iou_score = np.sum(intersection) / np.sum(union)
    return iou_score

iou = iou_score(y_true, y_pred)
print(f"IoU: {iou}")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(n_class=1).to(device)
model.load_state_dict(torch.load("model_bce.pth", map_location = device))

import matplotlib.pyplot as plt

image_idx = 10
for image_idx in range(150, 155):
    image = train_dataset[image_idx][0]
    image_infer = train_dataset[image_idx][1]
    output = model(image.unsqueeze(0))
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Create a figure and a set of subplots

    axs[0].imshow(np.transpose(image.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ultrasound Image")
    axs[1].imshow(np.transpose(image_infer.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ground Truth Mask")
    axs[2].imshow(np.transpose(torch.sigmoid(output.squeeze(0)).cpu().detach().numpy(), (1, 2, 0)), cmap = "gray", label = "Predicted Mask")

    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------------------------------------------------------------")

class IoULoss(nn.Module):
    def __init__(self, eps=1e-6):
        super(IoULoss, self).__init__()
        self.eps = eps

    def forward(self, inputs, targets):
        # Compute intersection
        intersection = (inputs * targets).sum()
        # Compute union
        total = (inputs + targets).sum()
        union = total - intersection

        iou = (intersection + self.eps) / (union + self.eps)
        return 1 - iou

class CombinedLoss(nn.Module):
    def __init__(self, alpha=0.8):
        super(CombinedLoss, self).__init__()
        self.alpha = alpha
        self.bce = nn.BCEWithLogitsLoss()
        self.iou = IoULoss()

    def forward(self, inputs, targets):
        return self.alpha * self.bce(inputs, targets) + (1 - self.alpha) * self.iou(inputs, targets)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_combine = UNet(n_class=1).to(device)
# Now use IoU as the loss function
criterion = CombinedLoss()
# Optimizer: Adam
optimizer = torch.optim.Adam(model_combine.parameters(), lr=0.001)
loss_train, loss_valid = train(model_combine, train_loader, val_loader, criterion, optimizer, n_epochs=20)

# Plot the training and validation loss
import matplotlib.pyplot as plt
plt.plot(loss_train, label='Training loss')
plt.plot(loss_valid, label='Validation loss')
plt.legend()
plt.show()

# Save the model
torch.save(model_combine.state_dict(), 'model_bce_iou_1.pth')

# Make predictions on the test set and use MAE as evaluation metric
from sklearn.metrics import mean_absolute_error

model_combine.eval()
y_true = []
y_pred = []
with torch.no_grad():
    for data in test_loader:
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model_combine(inputs)
        y_true.append(labels.cpu().numpy())
        y_pred.append(outputs.cpu().numpy())
y_true = np.concatenate(y_true)
y_pred = np.concatenate(y_pred)
mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())
print(f"Mean Absolute Error: {mae}")
def iou_score(y_true, y_pred):
    intersection = np.logical_and(y_true, y_pred)
    union = np.logical_or(y_true, y_pred)
    iou_score = np.sum(intersection) / np.sum(union)
    return iou_score

iou = iou_score(y_true, y_pred)
print(f"IoU: {iou}")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_combine = UNet(n_class=1).to(device)
model_combine.load_state_dict(torch.load("model_bce_iou_1.pth", map_location = device))

for image_idx in range(170, 180):
    image = train_dataset[image_idx][0]
    image_infer = train_dataset[image_idx][1]
    output = model_combine(image.unsqueeze(0))
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Create a figure and a set of subplots

    axs[0].imshow(np.transpose(image.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ultrasound Image")
    axs[1].imshow(np.transpose(image_infer.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ground Truth Mask")
    axs[2].imshow(np.transpose(torch.sigmoid(output.squeeze(0)).cpu().detach().numpy(), (1, 2, 0)), cmap = "gray", label = "Predicted Mask")

    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------------------------------------------------------------")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_mse = UNet(n_class=1).to(device)
# Now use IoU as the loss function
criterion = nn.MSELoss()
# Optimizer: Adam
optimizer = torch.optim.Adam(model_mse.parameters(), lr=0.001)
loss_train, loss_valid = train(model_mse, train_loader, val_loader, criterion, optimizer, n_epochs=20)

# Plot the training and validation loss
import matplotlib.pyplot as plt
plt.plot(loss_train, label='Training loss')
plt.plot(loss_valid, label='Validation loss')
plt.legend()
plt.show()

# Save the model
torch.save(model_mse.state_dict(), 'model_mse.pth')

# Make predictions on the test set and use MAE as evaluation metric
from sklearn.metrics import mean_absolute_error

model_mse.eval()
y_true = []
y_pred = []
with torch.no_grad():
    for data in test_loader:
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model_mse(inputs)
        y_true.append(labels.cpu().numpy())
        y_pred.append(outputs.cpu().numpy())
y_true = np.concatenate(y_true)
y_pred = np.concatenate(y_pred)
mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())
print(f"Mean Absolute Error: {mae}")
def iou_score(y_true, y_pred):
    intersection = np.logical_and(y_true, y_pred)
    union = np.logical_or(y_true, y_pred)
    iou_score = np.sum(intersection) / np.sum(union)
    return iou_score

iou = iou_score(y_true, y_pred)
print(f"IoU: {iou}")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_mse = UNet(n_class=1).to(device)
model_mse.load_state_dict(torch.load("model_mse.pth", map_location = device))

for image_idx in range(170, 180):
    image = train_dataset[image_idx][0]
    image_infer = train_dataset[image_idx][1]
    output = model_mse(image.unsqueeze(0))
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Create a figure and a set of subplots

    axs[0].imshow(np.transpose(image.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ultrasound Image")
    axs[1].imshow(np.transpose(image_infer.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ground Truth Mask")
    axs[2].imshow(np.transpose(torch.sigmoid(output.squeeze(0)).cpu().detach().numpy(), (1, 2, 0)), cmap = "gray", label = "Predicted Mask")

    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------------------------------------------------------------")

# Infer the test set with no ground truth
class UltrasoundTestDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.imgs = sorted([x for x in os.listdir(img_dir)])

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.imgs[idx])
        image = Image.open(img_path)
        if self.transform:
            image = self.transform(image)
        return image

# Create the dataset
transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),
                                transforms.Resize((256, 256)),
                                transforms.ToTensor()])
test_dataset = UltrasoundTestDataset(img_dir="test_set", transform=transform)

# Create the dataloader
tester_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

# Inference by plotting the first 5 images with combined loss model
model_combine.eval()
for image_idx in range(5):
    image = test_dataset[image_idx]
    output = model_combine(image.unsqueeze(0))
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # Create a figure and a set of subplots

    axs[0].imshow(np.transpose(image.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ultrasound Image")
    axs[1].imshow(np.transpose(torch.sigmoid(output.squeeze(0)).cpu().detach().numpy(), (1, 2, 0)), cmap = "gray", label = "Predicted Mask")

    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------------------------------------------------------------")

# Inference by plotting the first 5 images with combined loss model
model_mse.eval()
for image_idx in range(5):
    image = test_dataset[image_idx]
    output = model_mse(image.unsqueeze(0))
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # Create a figure and a set of subplots

    axs[0].imshow(np.transpose(image.cpu().numpy(), (1, 2, 0)), cmap = "gray", label = "Ultrasound Image")
    axs[1].imshow(np.transpose(torch.sigmoid(output.squeeze(0)).cpu().detach().numpy(), (1, 2, 0)), cmap = "gray", label = "Predicted Mask")

    plt.show()
    print("---------------------------------------------------------------------------------------------------------------------------------------------------------------------------")